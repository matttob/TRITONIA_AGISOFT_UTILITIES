{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975e0aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from platform import python_version\n",
    "import io\n",
    "import math\n",
    "import csv\n",
    "import numpy as np\n",
    "from csv import DictWriter\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import shutil\n",
    "from statistics import mode\n",
    "\n",
    "import pytesseract\n",
    "# Provide the path of the install location of Tesseract-OCR in your system\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\MatthewToberman\\miniconda3\\envs\\agisoft_testing\\Library\\bin\\tesseract.exe'\n",
    "tessdata_dir_config = r'--tessdata-dir \"C:\\Users\\MatthewToberman\\miniconda3\\pkgs\\tesseract-5.0.1-h17c68af_0\\share\\tessdata\"'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59b22765",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'bool' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mw:\\MATT\\TRITONIA_AGISOFT_UTILITIES\\rov_video_frame_extraction.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/w%3A/MATT/TRITONIA_AGISOFT_UTILITIES/rov_video_frame_extraction.ipynb#ch0000001?line=126'>127</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(text_meta_datas_no_nan) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/w%3A/MATT/TRITONIA_AGISOFT_UTILITIES/rov_video_frame_extraction.ipynb#ch0000001?line=127'>128</a>\u001b[0m     text_meta_datas_no_nan \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mno_metaa\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/w%3A/MATT/TRITONIA_AGISOFT_UTILITIES/rov_video_frame_extraction.ipynb#ch0000001?line=128'>129</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39;49m(text_meta_datas_no_nan \u001b[39m!=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m ) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/w%3A/MATT/TRITONIA_AGISOFT_UTILITIES/rov_video_frame_extraction.ipynb#ch0000001?line=129'>130</a>\u001b[0m     text_meta_datas_no_nan \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mno_metaa\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/w%3A/MATT/TRITONIA_AGISOFT_UTILITIES/rov_video_frame_extraction.ipynb#ch0000001?line=131'>132</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(text_meta_datas_no_nan) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m  \u001b[39m2\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'bool' has no len()"
     ]
    }
   ],
   "source": [
    "# Enter path of highest tier of video files \n",
    "# Enter path of highest tier of video files \n",
    "video_files_highest_directory = Path(r\"W:\\CHEVRON\\AA_DONT_CHANGE_Chevron2022\\GS-MIKE\")\n",
    "video_file_paths_mpg = [str(pp) for pp in video_files_highest_directory.glob(\"**/*.mpg\")]\n",
    "video_file_paths_asf = [str(pp) for pp in video_files_highest_directory.glob(\"**/*.asf\")]\n",
    "video_file_paths = video_file_paths_mpg + video_file_paths_asf\n",
    "\n",
    "\n",
    "display_plots = 0\n",
    "\n",
    "for video_file_name in video_file_paths:\n",
    "\n",
    "    image_file_path = video_file_name.split('\\\\')\n",
    "    cropped_image_folder = ('\\\\'.join(map(str, image_file_path[0:-1])))\n",
    "    cropped_image_folder = cropped_image_folder + '\\\\FRAMES_' + image_file_path[-1].split('@')[-1].split('.')[0]\n",
    "    os.mkdir(cropped_image_folder)\n",
    "    # Read the video from specified path this could clearly be changed to a file open box\n",
    "    cap = cv2.VideoCapture(video_file_name)  \n",
    "    # find length of entire video in frames\n",
    "    total_frame_number = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # find frame rate of video\n",
    "    frame_rate=cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    #  find the time at the end of video so can use this if entire video is required\n",
    "    video_end_time_mins,video_end_time_secs  = divmod(math.floor(total_frame_number / frame_rate), 60)\n",
    "\n",
    "    # Enter video file start time and end time and frame interval for frame grab \n",
    "    start_time_mins=0\n",
    "    start_time_secs=1\n",
    "    end_time_mins=video_end_time_mins\n",
    "    end_time_secs=video_end_time_secs\n",
    "    frame_interval=50\n",
    "\n",
    "    # find start and end frames coorresponding to start and end times\n",
    "    start_frame=math.floor((start_time_mins*60*frame_rate)+(start_time_secs*frame_rate))\n",
    "    end_frame=math.floor((end_time_mins*60*frame_rate)+(end_time_secs*frame_rate))\n",
    "\n",
    "\n",
    "    frame_counter = 0\n",
    "    text_depth_nums = []\n",
    "    text_meta_datas = []\n",
    "    # Loop through specified frames \n",
    "    # for i in range(1,2,1):\n",
    "    for i in range(start_frame,end_frame,frame_interval):\n",
    "        \n",
    "    \n",
    "        # choose specified frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES,i)\n",
    "        # read specified frame\n",
    "        ret, frame = cap.read()\n",
    "        # First crop banner text from image as otherwise this can be included in the blurr detection process and make the image appear in focus. These banners will need to be removed for agisoft proccesing anyhow\n",
    "        #set pixel value of top of cropped image\n",
    "        vert_crop_start = 1\n",
    "        #set pixel value of bottom of cropped image\n",
    "        vert_crop_end = frame.shape[0]\n",
    "        horz_crop_start = 1\n",
    "        horz_crop_end = frame.shape[1]\n",
    "        # Crop frame\n",
    "        crop_frame = frame[vert_crop_start:vert_crop_end, horz_crop_start:horz_crop_end]\n",
    "        # create time stamp for frame file name\n",
    "        fractional_mins, whole_mins = math.modf((i/frame_rate)/60)\n",
    "\n",
    "        # # select area of image with required text for meta data only from first frame shod change this until only an acceptable value is recieved \n",
    " \n",
    "        text_frame_meta_data_horz_start = 0 \n",
    "        text_frame_meta_data_horz_end = 800\n",
    "        text_frame_meta_data_vert_start = 650\n",
    "        text_frame_meta_data_vert_end = 690\n",
    "        text_frame_meta_data =  frame[ text_frame_meta_data_vert_start:text_frame_meta_data_vert_end,text_frame_meta_data_horz_start:text_frame_meta_data_horz_end]\n",
    "        text_meta_data = pytesseract.image_to_string(text_frame_meta_data, config=tessdata_dir_config)\n",
    "        if len(text_meta_data) < 4:\n",
    "            text_meta_data = 'notextfound'\n",
    "        else:\n",
    "            text_meta_data =  ''.join(e for e in text_meta_data if e.isalnum())\n",
    "            text_meta_data =  ''.join(e for e in text_meta_data if e.isalnum())\n",
    "        text_meta_datas.append(text_meta_data)\n",
    "        \n",
    "        # select area of image with required text for depth data\n",
    "        text_frame_depth_data_horz_start = 440\n",
    "        text_frame_depth_data_horz_end = 700\n",
    "        text_frame_depth_data_vert_start = 1\n",
    "        text_frame_depth_data_vert_end = 60\n",
    "        text_frame_depth_data =  frame[ text_frame_depth_data_vert_start:text_frame_depth_data_vert_end,text_frame_depth_data_horz_start:text_frame_depth_data_horz_end]\n",
    "        text_depth_data = pytesseract.image_to_string(text_frame_depth_data, config=tessdata_dir_config)        \n",
    "        if len(text_depth_data) > 0:\n",
    "            if len((re.findall(\"\\d+\", text_depth_data))) >0 :\n",
    "                text_depth_num = (re.findall(\"\\d+\", text_depth_data))\n",
    "                text_depth_num = (''.join(text_depth_num))\n",
    "                if len(text_depth_num) > 0:\n",
    "                    text_depth_num =int(text_depth_num)\n",
    "                    if text_depth_num < 5 or text_depth_num > 100:\n",
    "                        text_depth_num = 'na'\n",
    "\n",
    "            else:\n",
    "                text_depth_num = 'na' \n",
    "        else:\n",
    "            text_depth_num = 'na'    \n",
    "        text_depth_nums.append(text_depth_num)\n",
    "\n",
    "\n",
    "\n",
    "        # if display_plots ==1:\n",
    "        #     fig,ax =plt.subplots() \n",
    "        #     ax.imshow(frame)\n",
    "        #     plt.title('Frame')\n",
    "        #     plt.show()\n",
    "\n",
    "        #     # show selected area for testing\n",
    "        #     plt.imshow(text_frame_meta_data)\n",
    "        #     plt.title('Meta Data')\n",
    "        #     plt.show()\n",
    "        #     print(text_meta_data)\n",
    "        #     # show selected area for testing\n",
    "        #     plt.imshow(text_frame_depth_data)\n",
    "        #     plt.title('Depth Data')\n",
    "        #     plt.show()\n",
    "        # if display_plots ==1:\n",
    "        #     print(text_depth_num)\n",
    "\n",
    "\n",
    "         # create and save jpegs\n",
    "        frame_image_name=cropped_image_folder + '/' 'Frame_'+str(i) + '_' + str(round(whole_mins)) + 'mins' + '_' + str(round(fractional_mins*60)) + 'secs_'  + '.jpg'\n",
    "        cv2.imwrite(frame_image_name,crop_frame)\n",
    "    #     frame_counter +=1\n",
    "    \n",
    "    \n",
    "    text_depth_nums_no_nan = ([num for num in text_depth_nums if num != 'na' ])\n",
    "    \n",
    "    text_meta_datas_no_nan  = ([meta for meta in text_meta_datas if meta != 'notextfound'])\n",
    "    if len(text_meta_datas_no_nan) < 2:\n",
    "        text_meta_datas_no_nan = 'no_metaa'\n",
    "        text_meta_datas_no_nan = 'no_metaa'\n",
    "\n",
    "    if len(text_meta_datas_no_nan) >=  2:\n",
    "        mode_text_meta_datas_no_nan = mode(text_meta_datas_no_nan)\n",
    "    else :\n",
    "        mode_text_meta_datas_no_nan = 'no_metaa'\n",
    "    if mode_text_meta_datas_no_nan == '':\n",
    "        mode_text_meta_datas_no_nan = 'no_metaa'\n",
    "    if len(text_depth_nums_no_nan) > 0:\n",
    "       shutil.move(cropped_image_folder ,'/'.join(cropped_image_folder.split('\\\\')[:-1]) + '/' + mode_text_meta_datas_no_nan[:-1]   + '_depth_'  + str(min(text_depth_nums_no_nan)) +'_' + str(max(text_depth_nums_no_nan)))\n",
    "    else:\n",
    "        shutil.move(cropped_image_folder ,'/'.join(cropped_image_folder.split('\\\\')[:-1]) + '/' + mode_text_meta_datas_no_nan[:-1]   + '_depth_NA')\n",
    "    print(mode_text_meta_datas_no_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ac144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e37da7554b3ad583697b6d4faddd18a939ee6452966fb8334273511d12ae2fd8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('agisoft_testing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
